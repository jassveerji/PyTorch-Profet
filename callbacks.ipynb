{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "> Callbacks used to train fastai model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callbacks.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from fastai.basics import LearnerCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class L1Loss(LearnerCallback):\n",
    "    def __init__(self, learn, beta=1e-2):\n",
    "        super().__init__(learn)\n",
    "        self.beta = beta\n",
    "    \n",
    "    def on_backward_end(self, **kwargss):\n",
    "        weights = {k:v for k,v in self.learn.model.named_parameters() \n",
    "                   if not 'bias' in k}\n",
    "        \n",
    "        for k, v in weights.items():\n",
    "            sign = torch.ones_like(v)\n",
    "            sign[v<0] = -1\n",
    "            v = v - self.beta * sign\n",
    "            self.learn.model.state_dict()[k].copy_(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_loss(model, dl, loss_func):\n",
    "    \"\"\"Calculate `loss_func` of `model` on `dl` in evaluation mode.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        N = 0\n",
    "        for xb,yb in dl:\n",
    "            # breakpoint()\n",
    "            if isinstance(xb, list):\n",
    "                loss += loss_func(model(*xb), yb) * len(yb)\n",
    "            else:\n",
    "                loss += loss_func(model(xb), yb) * len(yb)\n",
    "            N += len(yb)\n",
    "        return loss / N\n",
    "                    \n",
    "class PrintLoss(LearnerCallback):\n",
    "    \"\"\"\n",
    "    Prints Loss in one line as opposed to fastai Printer\n",
    "    \"\"\"\n",
    "    def __init__(self, learn):\n",
    "        super().__init__(learn)\n",
    "        \n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        train_loss = _get_loss(self.learn.model, self.learn.data.train_dl, loss_func=self.learn.loss_func)\n",
    "        val_loss = _get_loss(self.learn.model, self.learn.data.valid_dl, loss_func=self.learn.loss_func)\n",
    "        \n",
    "        epoch = kwargs['epoch']\n",
    "        n_epochs = kwargs['n_epochs']\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{n_epochs} Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 99_index.ipynb.\n",
      "Converted blocks.ipynb.\n",
      "Converted callbacks.ipynb.\n",
      "Converted data.ipynb.\n",
      "Converted model.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
